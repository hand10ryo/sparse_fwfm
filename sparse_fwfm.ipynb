{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uY4KXKRD6PUD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import csr_matrix, hstack, coo_matrix\n",
    "from tqdm import tqdm\n",
    "import sparse as sp\n",
    "from opt_einsum import contract\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "M-dfEDlY6GFy",
    "outputId": "1f31df7e-6f66-4b29-aedc-eecc5f93f27d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (11,12,13,14,15,16,17,18,27,28,29,30,31,32,33,34,35,36,37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AREA</th>\n",
       "      <th>Salary</th>\n",
       "      <th>domein</th>\n",
       "      <th>job[0]</th>\n",
       "      <th>job[1]</th>\n",
       "      <th>job[2]</th>\n",
       "      <th>job[3]</th>\n",
       "      <th>...</th>\n",
       "      <th>importance[15]</th>\n",
       "      <th>importance[16]</th>\n",
       "      <th>importance[17]</th>\n",
       "      <th>importance[18]</th>\n",
       "      <th>Company</th>\n",
       "      <th>most_importance</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence</th>\n",
       "      <th>factor</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>男性</td>\n",
       "      <td>60</td>\n",
       "      <td>神奈川県</td>\n",
       "      <td>1000万円未満</td>\n",
       "      <td>1-1-18：医療保険</td>\n",
       "      <td>運送・輸送業</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>チューリッヒ生命</td>\n",
       "      <td>保障内容に対する保険料</td>\n",
       "      <td>Q2_1</td>\n",
       "      <td>申込み窓口の豊富さ（取扱い店舗、ネット申込み、保険営業員 等）</td>\n",
       "      <td>加入手続き</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>男性</td>\n",
       "      <td>60</td>\n",
       "      <td>神奈川県</td>\n",
       "      <td>1000万円未満</td>\n",
       "      <td>1-1-18：医療保険</td>\n",
       "      <td>運送・輸送業</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>チューリッヒ生命</td>\n",
       "      <td>保障内容に対する保険料</td>\n",
       "      <td>Q2_2</td>\n",
       "      <td>加入手続きの容易さ（記入事項の分かりやすさ、提出書類の内容、情報提供、等を含む）</td>\n",
       "      <td>加入手続き</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>男性</td>\n",
       "      <td>60</td>\n",
       "      <td>神奈川県</td>\n",
       "      <td>1000万円未満</td>\n",
       "      <td>1-1-18：医療保険</td>\n",
       "      <td>運送・輸送業</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>チューリッヒ生命</td>\n",
       "      <td>保障内容に対する保険料</td>\n",
       "      <td>Q2_3</td>\n",
       "      <td>加入手続き完了まで（契約完了まで）のスピード</td>\n",
       "      <td>加入手続き</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>男性</td>\n",
       "      <td>60</td>\n",
       "      <td>神奈川県</td>\n",
       "      <td>1000万円未満</td>\n",
       "      <td>1-1-18：医療保険</td>\n",
       "      <td>運送・輸送業</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>チューリッヒ生命</td>\n",
       "      <td>保障内容に対する保険料</td>\n",
       "      <td>Q2_4</td>\n",
       "      <td>商品内容の分かりやすさ</td>\n",
       "      <td>商品内容</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>男性</td>\n",
       "      <td>60</td>\n",
       "      <td>神奈川県</td>\n",
       "      <td>1000万円未満</td>\n",
       "      <td>1-1-18：医療保険</td>\n",
       "      <td>運送・輸送業</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>チューリッヒ生命</td>\n",
       "      <td>保障内容に対する保険料</td>\n",
       "      <td>Q2_5</td>\n",
       "      <td>商品内容の充実度（特約等を含む）</td>\n",
       "      <td>商品内容</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index SEX  AGE  AREA    Salary       domein  job[0] job[1] job[2] job[3]  \\\n",
       "0      0  男性   60  神奈川県  1000万円未満  1-1-18：医療保険  運送・輸送業    NaN    NaN    NaN   \n",
       "1      0  男性   60  神奈川県  1000万円未満  1-1-18：医療保険  運送・輸送業    NaN    NaN    NaN   \n",
       "2      0  男性   60  神奈川県  1000万円未満  1-1-18：医療保険  運送・輸送業    NaN    NaN    NaN   \n",
       "3      0  男性   60  神奈川県  1000万円未満  1-1-18：医療保険  運送・輸送業    NaN    NaN    NaN   \n",
       "4      0  男性   60  神奈川県  1000万円未満  1-1-18：医療保険  運送・輸送業    NaN    NaN    NaN   \n",
       "\n",
       "   ... importance[15] importance[16] importance[17] importance[18]   Company  \\\n",
       "0  ...            NaN            NaN            NaN            NaN  チューリッヒ生命   \n",
       "1  ...            NaN            NaN            NaN            NaN  チューリッヒ生命   \n",
       "2  ...            NaN            NaN            NaN            NaN  チューリッヒ生命   \n",
       "3  ...            NaN            NaN            NaN            NaN  チューリッヒ生命   \n",
       "4  ...            NaN            NaN            NaN            NaN  チューリッヒ生命   \n",
       "\n",
       "  most_importance question                                  sentence factor  \\\n",
       "0     保障内容に対する保険料     Q2_1           申込み窓口の豊富さ（取扱い店舗、ネット申込み、保険営業員 等）  加入手続き   \n",
       "1     保障内容に対する保険料     Q2_2  加入手続きの容易さ（記入事項の分かりやすさ、提出書類の内容、情報提供、等を含む）  加入手続き   \n",
       "2     保障内容に対する保険料     Q2_3                    加入手続き完了まで（契約完了まで）のスピード  加入手続き   \n",
       "3     保障内容に対する保険料     Q2_4                               商品内容の分かりやすさ   商品内容   \n",
       "4     保障内容に対する保険料     Q2_5                          商品内容の充実度（特約等を含む）   商品内容   \n",
       "\n",
       "  SCORE  \n",
       "0     6  \n",
       "1     6  \n",
       "2     6  \n",
       "3     6  \n",
       "4     6  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/'\n",
    "df = pd.read_csv(path + \"CrossDomain_2years.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby([\"domein\", \"Company\"])[\"index\"].nunique().reset_index().rename(columns = {\"index\":\"count\"})\n",
    "df = pd.merge(df, df_count, on=[\"domein\", \"Company\"])\n",
    "df = df[df[\"count\"] > 100].drop(\"count\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lgYqZwNDMLSg"
   },
   "outputs": [],
   "source": [
    "df_X = df[[\"SEX\", \"AGE\", \"Salary\", \"domein\", \"job[0]\", \"job[1]\", \"importance[0]\", \"importance[1]\", \"Company\", \"question\", \"sentence\", \"factor\"]].fillna(\"Nan\").copy()\n",
    "df_y = df[\"SCORE\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H2_q4PZILehQ"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, X_train:pd.DataFrame, y_train:pd.Series):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, X_test: pd.DataFrame) -> pd.Series:\n",
    "        # predict here\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class FwFM(Model):\n",
    "    \"\"\" Field weighted Factorization Machines implemented by scipy.sparse.csr_matrix\n",
    "    See colaboratory notebook https://colab.research.google.com/drive/1AsOLL_7ON_Fl22rIJ3RngvLAxe5IOmBh?usp=sharing \n",
    "    or original paper https://arxiv.org/pdf/1806.03514.pdf  for details.\n",
    "\n",
    "    requirements:\n",
    "        pandas,\n",
    "        numpy,\n",
    "        sklearn,\n",
    "        scipy,\n",
    "        tqdm,\n",
    "        opt_einsum\n",
    "    \"\"\"\n",
    "    def __init__(self, df_X: pd.DataFrame, df_y: pd.Series, dim:int =8, lr:float = 1e-3, \n",
    "                 n_epoch: int = 10, n_batch: int =256, ignore_interactions : list=[], train:bool=True, \n",
    "                 lam_w: float = 0, lam_v: float = 0, lam_r: float = 0):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            df_X [pd.DataFrame] : Explanatory variables (all columns are categorical)\n",
    "            df_y [pd.Series] : Objective variable\n",
    "            dim [int] : a number of dimention of embeddings.\n",
    "            lr [float] : learning rate\n",
    "            n_epoch [int] : a number of epoch/\n",
    "            n_batch [int] : a number of sample in mini-batch.\n",
    "            ignore_interactions [list] : element is pair of fields which you ignored interaction.\n",
    "            train [bool] : wheter run train or not when initializing.\n",
    "            lam_w [float] : weight of l2 norm for w.\n",
    "            lam_v [float] : weight of l2 norm for v.\n",
    "            lam_r [float] : weight of l2 norm for r.\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.lr = lr\n",
    "        self.n_epoch = n_epoch \n",
    "        self.n_batch = n_batch \n",
    "        self.ignore_interactions = ignore_interactions\n",
    "        self.lam_w = lam_w\n",
    "        self.lam_v = lam_v\n",
    "        self.lam_r = lam_r\n",
    "\n",
    "        self._preprocess(df_X, df_y)\n",
    "        if train:\n",
    "            self.train()\n",
    "\n",
    "    def _preprocess(self, df_X: pd.DataFrame,  df_y: pd.Series):\n",
    "        self.fields = df_X.columns \n",
    "        self.fields_dir = {}\n",
    "\n",
    "        field_start_idx = 0\n",
    "        for i, field in enumerate(self.fields):\n",
    "            ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "            X_field = ohe.fit_transform(df_X[[field]])\n",
    "            cols = ohe.categories_[0]\n",
    "\n",
    "            if i == 0:\n",
    "                X = csr_matrix(X_field)\n",
    "            else:\n",
    "                X = hstack([X, X_field])\n",
    "\n",
    "            self.fields_dir[field] = {\n",
    "                \"field_idx\":i,\n",
    "                \"start_idx\": field_start_idx, \n",
    "                \"end_idx\": field_start_idx + len(cols), \n",
    "                \"cols\": deepcopy(cols),\n",
    "                \"encoder\": deepcopy(ohe), \n",
    "            }\n",
    "            field_start_idx += len(cols)\n",
    "\n",
    "        self.b = 0\n",
    "        self.w = np.random.rand(X.shape[1]) / 10\n",
    "        self.v = np.random.rand(X.shape[1], self.dim) / 10\n",
    "        self.r = np.random.rand(len(self.fields), len(self.fields))/ 10\n",
    "        self.r_mask = np.ones([len(self.fields), len(self.fields)])\n",
    "\n",
    "        for i in range(len(self.fields)):\n",
    "            for j in range(i, len(self.fields)):\n",
    "                self.r_mask[i, j] = 0\n",
    "\n",
    "        for interaction in self.ignore_interactions:\n",
    "            field_i, field_j = tuple(interaction)\n",
    "            field_i_idx = self.fields_dir[field_i][\"field_idx\"]\n",
    "            field_j_idx = self.fields_dir[field_j][\"field_idx\"]\n",
    "            self.r_mask[field_i_idx, field_j_idx] = 0\n",
    "            self.r_mask[field_j_idx, field_i_idx] = 0\n",
    "\n",
    "        self.r = self.r * self.r_mask\n",
    "    \n",
    "        self.m2f = np.zeros([X.shape[1], len(self.fields)])\n",
    "        for i, field in enumerate(self.fields):\n",
    "            self.m2f[np.arange(self.fields_dir[field][\"start_idx\"], self.fields_dir[field][\"end_idx\"]), i] = 1  \n",
    "\n",
    "        self.X = csr_matrix(X)\n",
    "        self.y = df_y.values\n",
    "\n",
    "    def train(self):\n",
    "        n_iter = int(self.X.shape[0] / self.n_batch)\n",
    "        indices = np.arange(self.X.shape[0])\n",
    "\n",
    "        for ep in range(self.n_epoch):\n",
    "            np.random.shuffle(indices)\n",
    "            for i in tqdm(range(n_iter)):\n",
    "                batch_indices = indices[self.n_batch * i : self.n_batch * (i + 1)]\n",
    "                X_batch = self.X[batch_indices]\n",
    "                y_batch = self.y[batch_indices]\n",
    "\n",
    "                y_hat = self.predict(X_batch)\n",
    "                a = -2 * (y_batch - y_hat)\n",
    "\n",
    "                dL_db = (a * 1).mean()\n",
    "                dL_dw = (self.der_w(X_batch, reduction=None).T * a) / a.shape\n",
    "                dL_dv = (a * self.der_v(X_batch, reduction=None)).mean(axis=2)\n",
    "                dL_dr = (a * self.der_r(X_batch, reduction=None)).mean(axis=2)\n",
    "                self.update(dL_db, dL_dw, dL_dv, dL_dr)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def der_w(self, X: csr_matrix, reduction=\"mean\") -> csr_matrix:\n",
    "        dw = X\n",
    "        if reduction == \"mean\":\n",
    "            dw = dw.mean(axis=0)\n",
    "\n",
    "        return dw\n",
    "\n",
    "    def der_v(self, X: csr_matrix, reduction=\"mean\") -> np.ndarray:\n",
    "        dv = contract(\"ni,if,fg,nj,jd,jg->idn\", X.A, self.m2f, self.r, X.A, self.v, self.m2f)\n",
    "        \n",
    "        if reduction == \"mean\":\n",
    "            dv = dv.mean(axis=2)\n",
    "        return dv\n",
    "\n",
    "    def der_r(self, X : csr_matrix, reduction=\"mean\") -> np.ndarray:\n",
    "        dr = contract(\"ni,id,if,fg,bj,jd,jg->fgn\", X.A, self.v, self.m2f, self.r_mask, X.A, self.v, self.m2f)\n",
    "        \n",
    "        if reduction == \"mean\":\n",
    "            dr = dr.mean(axis=2)\n",
    "\n",
    "        return dr\n",
    "\n",
    "    def constraint_r(self, r):\n",
    "        return \n",
    "\n",
    "    def update(self, dL_db, dL_dw, dL_dv, dL_dr):\n",
    "        self.b -= dL_db * self.lr \n",
    "        self.w -= dL_dw * self.lr\n",
    "        self.v -= dL_dv * self.lr\n",
    "        self.r -= (dL_dr * self.lr + self.lam_r * self.r)\n",
    "\n",
    "\n",
    "    def predict(self, X: csr_matrix):\n",
    "        y_hat = contract(\"ni,id,if,fg,nj,jd,jg->n\", X.A, self.v, self.m2f, self.r, X.A, self.v, self.m2f)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "    def convert_sparse(self, df_X: pd.DataFrame):\n",
    "        for i, field in enumerate(self.fields):\n",
    "            X_field = self.fields_dir[field][\"encoder\"].transform(df_X[[field]])\n",
    "            if i == 0:\n",
    "                X = csr_matrix(X_field)\n",
    "            else:\n",
    "                X = hstack([X, X_field])\n",
    "        return csr_matrix(X)\n",
    "\n",
    "    def __call__(self, df_X: pd.DataFrame, chunk_size = 1024):\n",
    "        X = self.convert_sparse(df_X)\n",
    "        indices = np.arange(X.shape[0])\n",
    "        n_splits = int(X.shape[0] / chunk_size)\n",
    "        y_hat = np.array([])\n",
    "        for chunk_indices in tqdm(np.array_split(indices, n_splits)):\n",
    "            y_hat = np.r_[y_hat, self.predict(X[chunk_indices])]\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOnzxzSRgDcz",
    "outputId": "03c4b54e-2451-4660-8560-ef5dcfe0b0f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [28:23<00:00,  2.50s/it]\n",
      "100%|██████████| 682/682 [26:18<00:00,  2.32s/it]\n",
      "100%|██████████| 682/682 [26:07<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8614387714670322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [26:11<00:00,  2.30s/it]\n",
      "100%|██████████| 682/682 [25:59<00:00,  2.29s/it]\n",
      "100%|██████████| 682/682 [26:04<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8457312274693052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 682/682 [26:06<00:00,  2.30s/it]\n",
      "100%|██████████| 682/682 [26:06<00:00,  2.30s/it]\n",
      "100%|██████████| 682/682 [25:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8625713584735466\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=3)\n",
    "userid = df[\"index\"].values\n",
    "for train_index, test_index in group_kfold.split(df_X, df_y, userid):\n",
    "    df_X_train, df_y_train = df_X.iloc[train_index], df_y.iloc[train_index]\n",
    "    df_X_test, df_y_test = df_X.iloc[test_index], df_y.iloc[test_index]\n",
    "    fwfm = FwFM(df_X_train, df_y_train, n_epoch=10)\n",
    "    y_hat = fwfm(df_X_test)\n",
    "    print(mean_squared_error(df_y_test.values, y_hat) ** 0.5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ANvga_FyaDm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sparse_fwfm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
